{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "   'axes.labelsize': 12,\n",
    "   'font.size': 10,\n",
    "   'legend.fontsize': 11,\n",
    "   'xtick.labelsize': 10,\n",
    "   'ytick.labelsize': 12,\n",
    "   'text.usetex': False,\n",
    "   'figure.figsize': [10, 2] # instead of 4.5, 4.5\n",
    "   }\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autolabel(rects, ses):\n",
    "    # attach some text labels\n",
    "    for rect, se in zip(rects, ses):\n",
    "        height = rect.get_height()\n",
    "        plt.axes().text(rect.get_x()+rect.get_width()/2., height+1.03*se, '{:2.3f}'.format(float(height)).lstrip('0'),\n",
    "                ha='center', va='bottom',fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment\n",
    "exp = 'mapping_loo'\n",
    "exp_label = 'Leave-one-out fMRI to Text Mapping'\n",
    "base_md = 'avg' #baseline model\n",
    "main_md = 'multi_srm' #main model\n",
    "\n",
    "# dictionaries\n",
    "cl_dict = {'class':{0:1/7,1:1/4,2:1/4,3:1/25},'rank':{0:1/2,1:1/2,2:1/2,3:1/2}} # chance level of each dataset\n",
    "feat_dict = {'multi_srm':[200,50,150],'all_srm':[50,125,50],'all_ica':[25,25,25],\\\n",
    "             'all_gica':[75,50,75],'all_dict':[200,150,75],'avg':[50,50,50]}\n",
    "roi_dict = {'dmn':0,'pt':1,'eac':2}\n",
    "md_dict = {'avg':'MNI','multi_srm':'MDSRM','ica':'ICA','gica':'Group-ICA','dict':'Dict','srm':'SRM'}\n",
    "ds_dict = {0:'GreenEyes',1:'Milky',2:'Vodka',3:'Sherlock'}\n",
    "actp_dict = {'class':'Classification Accuracy','rank':'Ranking Accuracy'}\n",
    "md_pre = ['all_']\n",
    "\n",
    "# path\n",
    "input_file = '../../output/accu_bar/{}/{}/{}_ds{}.npz' #exp,roi,model,ds\n",
    "output_path = '../../output/figures/{}/' #exp\n",
    "output_file = output_path+'{}_{}_ds{}' #roi,accu_type,ds\n",
    "if not os.path.exists(output_path.format(exp)):\n",
    "    os.makedirs(output_path.format(exp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_accu_all = [0.1,0.7] #accuracy for classification and ranking plots\n",
    "# datasets = [3]\n",
    "max_accu_all = [1.2,1.5] #accuracy for classification and ranking plots\n",
    "datasets = [1,2]\n",
    "model_all = ['ica','gica','dict','srm']\n",
    "roi_all = ['dmn','pt','eac']\n",
    "accu_type = ['class','rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mean = [] # length # of roi\n",
    "all_se = [] # length # of roi\n",
    "# aggregate each roi,each type\n",
    "for roi in roi_all:\n",
    "    roi_mean = []\n",
    "    roi_se = []\n",
    "    for ac_tp in accu_type:\n",
    "        roi_mean.append([])\n",
    "        roi_se.append([])\n",
    "    for ds in datasets:\n",
    "        # baseline model\n",
    "        ws=np.load(input_file.format(exp,roi,base_md,ds))\n",
    "        for r,ac_tp in enumerate(accu_type):\n",
    "            roi_mean[r].append(ws[ac_tp+'_mean'].item())\n",
    "            roi_se[r].append(ws[ac_tp+'_se'].item())\n",
    "        # add comparison models\n",
    "        for model in model_all: \n",
    "            for pre in md_pre:\n",
    "                ws=np.load(input_file.format(exp,roi,pre+model,ds))\n",
    "                for r,ac_tp in enumerate(accu_type):\n",
    "                    roi_mean[r].append(ws[ac_tp+'_mean'].item())\n",
    "                    roi_se[r].append(ws[ac_tp+'_se'].item())\n",
    "        # main model\n",
    "        ws=np.load(input_file.format(exp,roi,main_md,ds))\n",
    "        for r,ac_tp in enumerate(accu_type):\n",
    "            roi_mean[r].append(ws[ac_tp+'_mean'].item())\n",
    "            roi_se[r].append(ws[ac_tp+'_se'].item())\n",
    "    all_mean.append(roi_mean)\n",
    "    all_se.append(roi_se)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot all roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width=1\n",
    "nmodel = len(model_all)*len(md_pre)+2 # number of models, including baseline model and main model\n",
    "ndata = len(datasets)\n",
    "group_width = 1.25*width*nmodel\n",
    "center_all = np.linspace(0,group_width*(ndata-1),ndata)\n",
    "# set colors\n",
    "base_color = 'lightgrey'\n",
    "main_color = 'red'\n",
    "color_all = ['mediumseagreen','dodgerblue','mediumorchid','gold'] # at most 4 methods to compare\n",
    "\n",
    "for m,roi in enumerate(roi_all):\n",
    "    for r,ac_tp,max_accu in zip(range(len(accu_type)),accu_type,max_accu_all):\n",
    "        # xtick \n",
    "        xtick_idx = []\n",
    "        xtick_name = []    \n",
    "        # dataset names\n",
    "        ds_idx = []\n",
    "        ds_name = []\n",
    "        plt.figure()\n",
    "        # configure bars\n",
    "        for i,(ds, center) in enumerate(zip(datasets,center_all)):\n",
    "            mean = list(all_mean[m][r][i*nmodel:(i+1)*nmodel])\n",
    "            se   = list(all_se[m][r][i*nmodel:(i+1)*nmodel])    \n",
    "            idx = np.arange(center,center+nmodel*width,width)\n",
    "            error_config = {'ecolor': '0','capsize':3}   \n",
    "            rects = plt.bar(idx, mean, yerr=se, align='center', error_kw=error_config, width = width-0.1)\n",
    "            # set colors\n",
    "            rects[0].set_color(base_color)\n",
    "            for rect_i in range(1,len(rects)-1):\n",
    "                rects[rect_i].set_color(color_all[rect_i-1])\n",
    "            rects[-1].set_color(main_color)\n",
    "            autolabel(rects,se)\n",
    "            ds_idx.append(center+(nmodel-1)*width/2)        \n",
    "            ds_name.append(ds_dict[ds])\n",
    "            # xtick names\n",
    "            xtick_idx.extend(idx)\n",
    "            xtick_name.append(md_dict[base_md])\n",
    "            for model in model_all:\n",
    "                feat = str(feat_dict[md_pre[0]+model][roi_dict[roi]])\n",
    "                xtick_name.append(md_dict[model]+'\\n k='+feat)\n",
    "            feat = str(feat_dict[main_md][roi_dict[roi]])\n",
    "            xtick_name.append(md_dict[main_md]+'\\n k='+feat)\n",
    "            \n",
    "        plt.xticks(xtick_idx,xtick_name)\n",
    "        plt.ylabel('Accuracy')\n",
    "        left_lim = center_all[0]-0.5*width-0.5\n",
    "        right_lim = center_all[-1]+(nmodel-0.5)*width+0.5\n",
    "        plt.xlim([left_lim,right_lim])\n",
    "        plt.ylim([0,max_accu])\n",
    "\n",
    "        # plot chance accuracy of each dataset\n",
    "        for d,center in enumerate(center_all):\n",
    "            cl = cl_dict[ac_tp][datasets[d]]\n",
    "            line = plt.plot([center-width, center+(nmodel+1)*width], [cl, cl], 'k-.', linewidth=2)\n",
    "\n",
    "        # Add texts\n",
    "        plt.text((right_lim+left_lim)/2, 1.2*max_accu, exp_label+' '+actp_dict[ac_tp]+', ROI: '+roi.upper(),fontsize=12,horizontalalignment='center', verticalalignment='bottom')\n",
    "        props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "        for d in range(len(datasets)):\n",
    "            plt.text(ds_idx[d],0.96*max_accu,ds_name[d],bbox=props,fontsize=12,horizontalalignment='center', verticalalignment='top')\n",
    "\n",
    "        # legend\n",
    "        legend_handle = []\n",
    "        legend_handle.append(mpatches.Patch(color=base_color, label=md_dict[base_md]))\n",
    "        for patch_i in range(len(model_all)):\n",
    "            legend_handle.append(mpatches.Patch(color=color_all[patch_i], label=md_dict[model_all[patch_i]]))\n",
    "        legend_handle.append(mpatches.Patch(color=main_color, label=md_dict[main_md]))        \n",
    "        l1 = plt.legend(handles=legend_handle,bbox_to_anchor=(0.,1.02,1.,.102),loc=3,ncol=len(model_all)+2,mode=\"expand\", borderaxespad=0.)\n",
    "        ax = plt.gca().add_artist(l1)\n",
    "        plt.legend(line ,['chance'],loc=2,ncol=1)\n",
    "\n",
    "    #     plt.savefig(output_file.format(exp,roi,ac_tp,datasets).replace(' ','')+'.eps', format='eps', dpi=200,bbox_inches='tight')\n",
    "        plt.savefig(output_file.format(exp,roi,ac_tp,datasets).replace(' ','')+'.pdf', format='pdf', dpi=200,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
